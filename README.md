# sensitive-data

## ğŸ“Œ VisÃ£o Geral

Este repositÃ³rio contÃ©m o pipeline completo para **preparo, processamento, anotaÃ§Ã£o, padronizaÃ§Ã£o e treinamento** de modelos de **Reconhecimento de Entidades Nomeadas (NER)** voltados Ã  **identificaÃ§Ã£o e desidentificaÃ§Ã£o de dados sensÃ­veis**.

O fluxo foi projetado para garantir:

- Qualidade e consistÃªncia dos dados  
- Rastreabilidade das etapas  
- Controle de volume  
- PadronizaÃ§Ã£o das anotaÃ§Ãµes no formato **IOB**  
- Reprodutibilidade cientÃ­fica  

---

## ğŸ—‚ï¸ Estrutura Geral do Pipeline

1. Recorte do dataset original  
2. SeleÃ§Ã£o de colunas relevantes  
3. Split do dataset em chunks  
4. ExtraÃ§Ã£o de entidades sensÃ­veis (NER via LLM)  
5. ConsolidaÃ§Ã£o dos resultados
6. PadronizaÃ§Ã£o e anÃ¡lise de tags IOB  
7. Converte do formato IOB para JSON
8. Treinamento e avaliaÃ§Ã£o de modelos NER  

---

# ğŸ”¹ PreparaÃ§Ã£o e AnotaÃ§Ã£o do Dataset

## âœ‚ï¸ Recorte de Dados

### Objetivo
Reduzir o dataset original, mantendo apenas registros relevantes ao contexto do estudo.

### Fonte dos Dados
`merged_all_columns_2019_ate_2023-003.csv`

### Script
`dataset/NER/recorte_base_de_dados.ipynb`

### DescriÃ§Ã£o
- Filtragem por municÃ­pio (ex.: MarabÃ¡)  
- Agrupamento por tipo de ocorrÃªncia (`consolidado`)  
- SeleÃ§Ã£o das **10 ocorrÃªncias mais frequentes**  
- PreservaÃ§Ã£o de todos os registros associados  

### SaÃ­da
`top_10_consolidado_maraba_full.csv`

---

## ğŸ§© SeleÃ§Ã£o de Colunas

### Objetivo
Manter apenas campos essenciais para processamento textual e rastreabilidade.

### Script
`dataset/NER/selecao_dados.ipynb`

### DescriÃ§Ã£o
- SeleÃ§Ã£o de identificadores e texto do relato  
- ReduÃ§Ã£o de ruÃ­do e custo computacional  

### SaÃ­da
`top_10_consolidado_maraba_reduzido_colunas.csv`

---

## ğŸ”€ Split do Dataset

### Objetivo
Dividir o dataset em partes menores para evitar problemas de memÃ³ria e permitir reprocessamento incremental.

### Script
`dataset/NER/split.py`

### DescriÃ§Ã£o
- Leitura do arquivo em blocos de 1000 registros  
- GeraÃ§Ã£o de arquivos independentes  

### SaÃ­da
`split/relatos_chunk_*.csv`

---

## ğŸ§  ExtraÃ§Ã£o de Entidades SensÃ­veis (NER)

### Objetivo
Identificar automaticamente dados sensÃ­veis utilizando o padrÃ£o **IOB**.

### Script
`dataset/NER/generate_openia.py`

### Entidades Identificadas
BANCO, CNH, CPF, EMPRESA, ENDEREÃ‡O, PESSOA, RG, TELEFONE, VEÃCULO, CNPJ, EMAIL

### DescriÃ§Ã£o
- Envio dos relatos para modelo via API  
- Retorno token a token com rÃ³tulos IOB  
- Filtragem apenas de entidades sensÃ­veis  

### SaÃ­da
`api_openia_relatos_chunk_*.csv`

---

## ğŸ”— ConsolidaÃ§Ã£o dos Resultados

### Objetivo
Unificar todas as anotaÃ§Ãµes em um Ãºnico dataset.

### Script
`dataset/NER/unir.py`

### SaÃ­da
`IOB_relatos_consolidado_chatgpt.csv`

---

## ğŸ§¹ PadronizaÃ§Ã£o e AnÃ¡lise de Tags IOB

### Objetivo
Corrigir inconsistÃªncias e gerar estatÃ­sticas confiÃ¡veis das entidades.

### Script
`dataset/NER/get_uniques.py`

### DescriÃ§Ã£o
- NormalizaÃ§Ã£o de tags  
- RemoÃ§Ã£o de ruÃ­dos  
- PreservaÃ§Ã£o do padrÃ£o B-/I-  
- GeraÃ§Ã£o de estatÃ­sticas  

### SaÃ­da
`IOB_relatos_consolidado_chatgpt_clear.csv`

---

## ğŸ§¹ Converte IOB para JSON

### Objetivo
Realiza conversÃ£o do formato IOB para JSON para ser utilizados no modelos transformers

### Script
`dataset/NER/iob_to_json.py`

### DescriÃ§Ã£o
- Transforma o formato IOB para JSON

### SaÃ­da
`output_chatgpt.json`

---

## âœ… Dataset Final

O dataset final Ã©:

- Consolidado e padronizado  
- Anotado em formato IOB  
- Livre de inconsistÃªncias  
- Pronto para:
  - Treinamento de modelos NER  
  - AvaliaÃ§Ãµes comparativas  
  - DesidentificaÃ§Ã£o e anonimizaÃ§Ã£o  
  - Pesquisas acadÃªmicas  

---

# ğŸ”¹ Treinamento de Modelos NER

## ğŸ¯ Objetivos

- Identificar dados sensÃ­veis automaticamente  
- Comparar **BiLSTM** e **Transformers (BERTimbau)**  
- Garantir reprodutibilidade e organizaÃ§Ã£o por execuÃ§Ã£o  

---

## ğŸ“‚ Dataset de Entrada

**Formato:** JSON com offsets de caracteres

```json
{
  "doc_id": "ex-001",
  "doc_text": "CPF de JoÃ£o da Silva Ã© 123.456.789-00",
  "entities": [
    { "start_offset": 0, "end_offset": 3, "label": "CPF" }
  ]
}
```

**Arquivo:**  
`dataset/output_chatgpt.json`

---

# ğŸ§  Treinamento com Transformers (BERTimbau)

## Modelo Base
- `neuralmind/bert-base-portuguese-cased`
- CabeÃ§a de Token Classification

## Split do Dataset
- Treino: 80%  
- ValidaÃ§Ã£o: 10%  
- Teste: 10%  

## ConfiguraÃ§Ã£o

| ParÃ¢metro | Valor |
|---------|------|
| MAX_LEN | 512 |
| EPOCHS | 1 |
| BATCH | 16 |
| Learning Rate | 3e-5 |
| Seed Base | 42 |

## ExecuÃ§Ãµes

Cada execuÃ§Ã£o gera um diretÃ³rio prÃ³prio:

```
runs/
â””â”€â”€ <model>__<dataset>__<timestamp>/
    â”œâ”€â”€ checkpoints/
    â”œâ”€â”€ eval/
    â”œâ”€â”€ model/
    â””â”€â”€ run_manifest.json
```

---

# ğŸ” Treinamento com BiLSTM

## VisÃ£o Geral
Modelo clÃ¡ssico baseado em redes recorrentes, com menor custo computacional.

**Script:**  
`dataset/training/ner-using-bidirectional-lstm.ipynb`

---

## ğŸ”¬ ComparaÃ§Ã£o entre Modelos

| Aspecto | BiLSTM | Transformer |
|------|------|-----------|
| PrÃ©-treinamento | NÃ£o | Sim |
| Custo computacional | Baixo | Alto |
| Contexto | MÃ©dio | Alto |
| Desempenho | Bom | Muito alto |
| Hardware | CPU/GPU leve | GPU recomendada |

---

## ğŸ’¾ Artefatos Gerados

### Transformer
- Modelo treinado  
- Tokenizer  
- Checkpoints  
- MÃ©tricas e matrizes de confusÃ£o  

### BiLSTM
- Pesos do modelo  
- HistÃ³rico de treino  
- MÃ©tricas  
- GrÃ¡ficos  

---

## âš–ï¸ Benchmark

ComparaÃ§Ã£o direta entre os modelos utilizando textos limpos para desidentificaÃ§Ã£o.

**Script:**  
`dataset/training/ner-using-bidirectional-lstm.ipynb`

---

## ğŸ“¦ ExtraÃ§Ã£o de Artefatos

GeraÃ§Ã£o consolidada de resultados e mÃ©tricas.

**Script:**  
`dataset/training/results_ner.ipynb`
